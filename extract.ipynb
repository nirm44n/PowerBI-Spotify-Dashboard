{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b8bf6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1748382a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nirma\\\\Projects\\\\Github\\\\Spotify-Historical-PowerBI\\\\Data'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.getcwd()\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "85bdcfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 JSON files in c:\\Users\\nirma\\Projects\\Github\\Spotify-Historical-PowerBI\\Data\n",
      "Processing: Streaming_History_Audio_2014-2017_0.json\n",
      "Processing: Streaming_History_Audio_2017-2018_1.json\n",
      "Processing: Streaming_History_Audio_2018-2019_2.json\n",
      "Processing: Streaming_History_Audio_2019-2021_3.json\n",
      "Processing: Streaming_History_Audio_2021-2023_5.json\n",
      "Processing: Streaming_History_Audio_2021_4.json\n",
      "Processing: Streaming_History_Audio_2023-2025_6.json\n",
      "Processing: Streaming_History_Audio_Test.json\n",
      "Total records loaded: 104397\n"
     ]
    }
   ],
   "source": [
    "# Get all JSON files in the Data directory\n",
    "import glob\n",
    "json_files = glob.glob(os.path.join(data_dir, \"*.json\"))\n",
    "print(f\"Found {len(json_files)} JSON files in {data_dir}\")\n",
    "\n",
    "all_records = []\n",
    "\n",
    "for file_path in json_files:\n",
    "    try:\n",
    "        print(f\"Processing: {os.path.basename(file_path)}\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            all_records.extend(data)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "\n",
    "print(f\"Total records loaded: {len(all_records)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "cbb373f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df = pd.DataFrame(all_records)\n",
    "spotify_df.drop(columns=['episode_name', 'episode_show_name', 'ip_addr', 'incognito_mode', 'offline_timestamp', 'offline', 'audiobook_title', 'audiobook_uri','audiobook_chapter_uri','audiobook_chapter_title', 'spotify_episode_uri'], inplace=True, errors='ignore')\n",
    "#spotify_df.info()\n",
    "spotify_df['ts'] = pd.to_datetime(spotify_df['ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "fa49f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df[['platform', 'ts']].drop_duplicates().sort_values(\"ts\", ascending=False).to_csv('platform.csv', index=False)\n",
    "#spotify_df['platform'] = spotify_dfvalue_counts().plot(kind='bar', title='Platform Distribution', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ea9601b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ts', 'platform', 'ms_played', 'conn_country',\n",
       "       'master_metadata_track_name', 'master_metadata_album_artist_name',\n",
       "       'master_metadata_album_album_name', 'spotify_track_uri', 'reason_start',\n",
       "       'reason_end', 'shuffle', 'skipped'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "08aa12a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nirma\\AppData\\Local\\Temp\\ipykernel_96620\\3747657065.py:45: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df.loc[df[platform_col].str.contains(pattern, case=False, na=False), new_col] = platform_name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique standardized platforms:\n",
      "['Amazon Echo' 'Android TV' 'Google Pixel'\n",
      " 'Partner android_sdk GOOGLE;pixel_xl;f87c03896d274ecf9d80f86e942202e1;9_arm64-v8a'\n",
      " 'Tesla' 'Windows' 'android' 'iOS']\n",
      "\n",
      "Platform distribution:\n",
      "platform_standardized\n",
      "iOS                                                                                 36504\n",
      "Amazon Echo                                                                         31615\n",
      "Windows                                                                             23375\n",
      "Google Pixel                                                                        11172\n",
      "Android TV                                                                            790\n",
      "android                                                                               726\n",
      "Tesla                                                                                 214\n",
      "Partner android_sdk GOOGLE;pixel_xl;f87c03896d274ecf9d80f86e942202e1;9_arm64-v8a        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def standardize_platforms(df, platform_col='platform', new_col='platform_standardized', inplace=True, print_stats=True):\n",
    "    \"\"\"\n",
    "    Standardize platform names in the given DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing platform information\n",
    "    platform_col : str, default 'platform'\n",
    "        Name of the column containing platform information\n",
    "    new_col : str, default 'platform_standardized'\n",
    "        Name of the new column to create with standardized platforms\n",
    "    inplace : bool, default False\n",
    "        Whether to modify the DataFrame in-place or return a copy\n",
    "    print_stats : bool, default True\n",
    "        Whether to print statistics about the standardized platforms\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with added column containing standardized platform names\n",
    "    pandas.Series\n",
    "        Platform distribution counts\n",
    "    \"\"\"\n",
    "    # Create a copy if not modifying in-place\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "    \n",
    "    # Initialize the new column with original platform values\n",
    "    df[new_col] = df[platform_col]\n",
    "    \n",
    "    # Standardize platforms using regex pattern matching\n",
    "    platform_mapping = {\n",
    "        # Pattern: standardized name\n",
    "        '^iOS|^ios$': 'iOS',\n",
    "        'Windows|windows|web_player|desktop|Linux': 'Windows',\n",
    "        '(Google, Pixel XL)': 'Google Pixel',\n",
    "        'Echo|not_applicable': 'Amazon Echo',\n",
    "        'Tesla': 'Tesla',\n",
    "        'cast|tizen|ps4|SCEI': 'Android TV'\n",
    "    }\n",
    "    \n",
    "    # Apply each mapping pattern\n",
    "    for pattern, platform_name in platform_mapping.items():\n",
    "        df.loc[df[platform_col].str.contains(pattern, case=False, na=False), new_col] = platform_name\n",
    "    \n",
    "    # Calculate platform distribution\n",
    "    platform_counts = df[new_col].value_counts()\n",
    "    \n",
    "    # Print statistics if requested\n",
    "    if print_stats:\n",
    "        print(\"Unique standardized platforms:\")\n",
    "        print(df[new_col].drop_duplicates().sort_values().values)\n",
    "        \n",
    "        print(\"\\nPlatform distribution:\")\n",
    "        print(platform_counts)\n",
    "    \n",
    "    return df, platform_counts\n",
    "\n",
    "# Apply the standardization function to the DataFrame\n",
    "spotify_df, platform_counts = standardize_platforms(spotify_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ae96863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df.drop(columns=['platform'], inplace=True, errors='ignore')\n",
    "spotify_df.rename(columns={\n",
    "    'platform_standardized': 'platform',\n",
    "    'conn_country': 'country',\n",
    "    'master_metadata_track_name': 'track_name',\n",
    "    'master_metadata_album_artist_name': 'artist_name',\n",
    "    'master_metadata_album_album_name': 'album_name',\n",
    "    },inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e4dd6511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of formatted text columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>album_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34165</th>\n",
       "      <td>Tera Hone Laga Hoon (From \"Ajab Prem Ki Ghazab...</td>\n",
       "      <td>Atif Aslam</td>\n",
       "      <td>Ajab Prem Ki Ghazab Kahani (Original Motion Pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101027</th>\n",
       "      <td>Ferxxoko</td>\n",
       "      <td>Joyce Santana</td>\n",
       "      <td>Ferxxoko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81365</th>\n",
       "      <td>Lovely (With Khalid)</td>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>Lovely (With Khalid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>Animals</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28642</th>\n",
       "      <td>Xo</td>\n",
       "      <td>Keywest</td>\n",
       "      <td>Cover Sessions - The Ladies Vol.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               track_name    artist_name  \\\n",
       "34165   Tera Hone Laga Hoon (From \"Ajab Prem Ki Ghazab...     Atif Aslam   \n",
       "101027                                           Ferxxoko  Joyce Santana   \n",
       "81365                                Lovely (With Khalid)  Billie Eilish   \n",
       "2732                                              Animals       Maroon 5   \n",
       "28642                                                  Xo        Keywest   \n",
       "\n",
       "                                               album_name  \n",
       "34165   Ajab Prem Ki Ghazab Kahani (Original Motion Pi...  \n",
       "101027                                           Ferxxoko  \n",
       "81365                                Lovely (With Khalid)  \n",
       "2732                                                    V  \n",
       "28642                   Cover Sessions - The Ladies Vol.1  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_text_columns(df, columns, inplace=False):\n",
    "    \"\"\"\n",
    "    Perform basic text formatting on specified columns in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing columns to format\n",
    "    columns : list of str\n",
    "        Column names to apply text formatting\n",
    "    inplace : bool, default False\n",
    "        Whether to modify the DataFrame in-place or return a copy\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with formatted text columns\n",
    "    \"\"\"\n",
    "    # Create a copy if not modifying in-place\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "    \n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            # Only process non-null values\n",
    "            mask = df[column].notna()\n",
    "            \n",
    "            # Step 1: Remove leading/trailing whitespace\n",
    "            df.loc[mask, column] = df.loc[mask, column].str.strip()\n",
    "            \n",
    "            # Step 2: Fix multiple spaces\n",
    "            df.loc[mask, column] = df.loc[mask, column].str.replace(r'\\s+', ' ', regex=True)\n",
    "            \n",
    "            # Step 3: Apply title case (capitalize first letter of each word)\n",
    "            df.loc[mask, column] = df.loc[mask, column].str.title()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply text formatting to track, artist, and album name columns\n",
    "columns_to_format = ['track_name', 'artist_name', 'album_name']\n",
    "spotify_df = format_text_columns(spotify_df, columns_to_format, inplace=True)\n",
    "\n",
    "# Show a sample of the formatted data\n",
    "print(\"Sample of formatted text columns:\")\n",
    "spotify_df[columns_to_format].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2b06225e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tracks: 23604\n",
      "Number of unique artists: 9751\n",
      "Number of unique albums: 17864\n",
      "\n",
      "Found 2722 tracks with names longer than 50 characters:\n",
      "                                              track_name\n",
      "22486  \"We Circle Through The Night, Consumed By Fire...\n",
      "22484  (What'S So Funny Bout) Peace, Love And Underst...\n",
      "28129  (What'S So Funny Bout) Peace, Love And Underst...\n",
      "23511  (What'S So Funny Bout) Peace, Love And Underst...\n",
      "23306  (You Make Me Feel Like) A Natural Woman - Reco...\n"
     ]
    }
   ],
   "source": [
    "# Verify text formatting and check for any issues\n",
    "print(f\"Number of unique tracks: {spotify_df['track_name'].nunique()}\")\n",
    "print(f\"Number of unique artists: {spotify_df['artist_name'].nunique()}\")\n",
    "print(f\"Number of unique albums: {spotify_df['album_name'].nunique()}\")\n",
    "\n",
    "# Check for any unusually long titles\n",
    "long_titles = spotify_df[spotify_df['track_name'].str.len() > 50].sort_values(by='track_name')\n",
    "if len(long_titles) > 0:\n",
    "    print(f\"\\nFound {len(long_titles)} tracks with names longer than 50 characters:\")\n",
    "    print(long_titles[['track_name']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "048bff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to c:\\Users\\nirma\\Projects\\Github\\Spotify-Historical-PowerBI\\Data\\spotify_data_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "spotify_df.to_csv(os.path.join(data_dir, 'spotify_data_cleaned.csv'), index=False)\n",
    "# Save the cleaned DataFrame to a CSV file\n",
    "print(f\"Cleaned data saved to {os.path.join(data_dir, 'spotify_data_cleaned.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e20a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
